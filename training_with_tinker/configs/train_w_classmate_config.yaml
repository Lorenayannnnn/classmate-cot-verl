data_args:
  #  Dataset
  dataset_name: gsm8k_minimal_answer_box_prompt
  #  Tokenization
  max_prompt_length: 1024

main_model_args:
  model_name_or_path: Qwen/Qwen3-0.6B
  generation_configs:
    max_tokens: 3072
    seed: ${training_args.seed}
    temperature: 1.0
    top_k: -1
    top_p: 1.0

classmate_model_args:
  model_name_or_path: meta-llama/Llama-3.2-1B-Instruct
  classmate_reward_weight: 1

  # vanilla_reward, remove_wo_cot, random_truncate, random_truncate_remove_wo_cot, random_truncate_step_wise_utility
  classmate_reward_type: vanilla_reward

  # always, no_classmate_when_main_incorrect, neg_classmate_when_main_incorrect
  use_classmate_main_cond: no_classmate_when_main_incorrect

  main_cot_keep_rate: 0.8   # only effective for vanilla_reward

  generation_configs:
    max_tokens: 4096
    seed: ${training_args.seed}
    temperature: 0
    top_k: 1
    top_p: 1.0

training_args:
  adv_estimator: grpo   # grpo, grpo_main_classmate_separated

  output_dir: outputs/${training_args.wandb_run_name}

  seed: 42
  epochs: 3
  total_ckpt_num: 10
  total_test_time_num: 10
  batch_size: 256
  group_size: 8   # for grpo
  micro_batch_size: 32
  lr_scheduler_type: "linear"
  resume_from_checkpoint: null

  optim:
    # AdamW by default
#    optimizer: AdamW
#    optimizer_impl: torch.optim
    learning_rate: 1.0e-06
    beta1: 0.9
    beta2: 0.999
    eps: 0.00000001
    weight_decay: 0.01
    grad_clip_norm: 1.0


  # wandb
#  wandb_usr: null
#  wandb_entity: "lorena-yantianyi1020"
  use_wandb: True
  wandb_project: classmate_cot_w_verl
  wandb_run_name: null

hydra:
  run:
    dir: ${training_args.output_dir}